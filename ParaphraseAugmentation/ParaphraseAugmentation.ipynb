{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# ParaphraseAugmentation\n",
    "\n",
    "Here we experiment with augmenting the dataset with paraphrases in order to see if the paraphrased options still yield similar stereotypical biases.\n",
    "\n",
    "Two approaches were attempted: \n",
    "+ An LLM-based approach *and* using the Parrot-paraphraser.\n",
    "\n",
    "Because the generated possible image descriptions follow a relatively canonical structure we can use **instruction-tuned LLMs** for this task too. Add feed linguistic information during the prompt creation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Main Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "### Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d13d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install parrot paraphraser\n",
    "%pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758abd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare Imports\n",
    "import os, sys, json\n",
    "import tabulate\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "8d496008",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "d4a27261",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import utils.utils as utils\n",
    "reload(utils)\n",
    "from utils.utils import \\\n",
    "    KVCache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some relevant folders for data persistence\n",
    "os.makedirs(\"./data/augmented\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some paths (e.g. to load, save data)\n",
    "\n",
    "DATASET_URL = \"https://raw.githubusercontent.com/K-Square-00/VLStereo/refs/heads/main/data/VLStereoSet.csv\"\n",
    "\n",
    "MODEL = \"meta.llama3-3-70b-instruct-v1:0\"\n",
    "\n",
    "MODEL = \"us.meta.llama3-3-70b-instruct-v1:0\"\n",
    "\n",
    "DATASET_SAVE_PATH = \"./data/VLStereoSet_augm.csv\"\n",
    "\n",
    "DEBUG = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259b6526",
   "metadata": {},
   "source": [
    "### Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "399321db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Download a file and store it in ./data\n",
    "def download_file(url, filename):\n",
    "    with open(filename, \"wb\") as file:\n",
    "        response = requests.get(url)\n",
    "        file.write(response.content)\n",
    "\n",
    "download_file(DATASET_URL, f\"data/{ DATASET_URL.split('/')[-1] }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c7d74ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter-out \"dead\" samples\n",
    "df = pd.read_csv(f\"data/{ DATASET_URL.split('/')[-1] }\")\n",
    "df = df.rename(columns={\"Imaeg URL\": \"image_url\"}).drop(columns=[\"Unnamed: 8\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parrot import Parrot\n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e04b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"stereotype\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e737edc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"anti-stereotype\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577a1a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.unrelated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed20918d",
   "metadata": {},
   "source": [
    "### Discard samples with unavailable-images KV-Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "2aa9b6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "kv = KVCache(\"../BiasConventionality/cache.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7f2910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get keys of files\n",
    "kv.cache.keys()\n",
    "df = df[df[\"image_url\"].isin(kv.cache.keys())] # discard 396 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### Build the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More code using the function \n",
    "import boto3\n",
    "import json\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "891de70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "PrettyPrinter = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290b3987",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "411eae7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_access_key = os.environ.get(\"AWS_ACCESS_KEY_ID\")\n",
    "aws_secret_key = os.environ.get(\"AWS_SECRET_ACCESS_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "92ec9415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the Amazon Bedrock client\n",
    "bedrock_client = boto3.client(\n",
    "    \tservice_name=\"bedrock-runtime\",\n",
    "    region_name=\"us-east-1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a90dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrock_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ccde35",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = df.iloc[10][\"stereotype\"]\n",
    "\n",
    "PrettyPrinter.pprint(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "98e8d5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "get_prompt1 = lambda sentence: f\"\"\"\n",
    "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "You are a helpful system generating paraphrases.<|eot_id|>\n",
    "<|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "Generate three paraphrases of the most pertinent noun phrase of the following statement and make sure it fits the rest of the sentence: { sentence }\n",
    "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8de8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "PrettyPrinter.pprint(get_prompt1(\"TEST TEST TEST\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "2148dd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_payload(prompt):\n",
    "    return {\n",
    "        \"prompt\": prompt,\n",
    "        \"max_gen_len\": 150,\n",
    "        \"temperature\": 0.2,\n",
    "        \"top_p\": 0.9,\n",
    "        }\n",
    "    \n",
    "payload = compile_payload(get_prompt1(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b3c4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "PrettyPrinter.pprint(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634c51d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(payload):\n",
    "    body = json.dumps(payload)\n",
    "\n",
    "    response = bedrock_client.invoke_model(\n",
    "        body=body, \n",
    "        modelId=MODEL,\n",
    "        )\n",
    "\n",
    "    return json.loads(response.get(\"body\").read())\n",
    "    # response_body\n",
    "\n",
    "response_body = get_response(payload)\n",
    "\n",
    "print(response_body.get(\"generation\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0096ab16",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_response = response_body.get(\"generation\")\n",
    "\n",
    "get_prompt2 = lambda pre_request, generated_response: f\"\"\"\n",
    "{ pre_request }\n",
    "{ generated_response }<|eot_id|>\n",
    "<|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "From the below response you provided, extract only the complete paraphrased sentences. Each sentence should be on a new line.\n",
    "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\"\n",
    "\n",
    "payload = compile_payload(get_prompt2(get_prompt1(sentence), generated_response))\n",
    "\n",
    "response_body_2 = get_response(payload)\n",
    "\n",
    "print(response_body_2.get(\"generation\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2c778b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_body_2.get(\"generation\").split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea4cddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "\n",
    "kv_p = KVCache(\"paraphrase-cache.pickle\")\n",
    "\n",
    "for i, row in islice(df.iterrows(), 3 if DEBUG else None):\n",
    "    for func in [\"stereotype\", \"anti-stereotype\", \"unrelated\"]:\n",
    "        sentence = row[func]\n",
    "        if kv_p.get(sentence):\n",
    "            paraphrases = kv_p.get(sentence)\n",
    "        else:\n",
    "            payload = compile_payload(get_prompt1(sentence))\n",
    "            response_body = get_response(payload)\n",
    "            generated_response = response_body.get(\"generation\")\n",
    "\n",
    "            payload = compile_payload(get_prompt2(get_prompt1(sentence), generated_response))\n",
    "            response_body_2 = get_response(payload)\n",
    "            paraphrases = response_body_2.get(\"generation\").split(\"\\n\")\n",
    "            \n",
    "            # add sentence-paraphrases to cache\n",
    "            kv_p.set(sentence, paraphrases)\n",
    "\n",
    "        for j, paraphrase in enumerate(paraphrases):\n",
    "            if paraphrase:\n",
    "                df.loc[i, f\"{ func }_augmented_{j}\"] = paraphrase\n",
    "                print(paraphrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f14ea7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "3b13d47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(DATASET_SAVE_PATH, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
